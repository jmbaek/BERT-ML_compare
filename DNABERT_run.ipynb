{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyN4Sw+LUvCcVBvINtClIKsC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmbaek/DNABERT/blob/master/DNABERT_run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/jerryji1993/DNABERT"
      ],
      "metadata": {
        "id": "Jbm9RAyeDA7w",
        "outputId": "c3a5de36-8ac3-4ff5-fa9a-d3f76deb28f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DNABERT'...\n",
            "remote: Enumerating objects: 766, done.\u001b[K\n",
            "remote: Counting objects: 100% (766/766), done.\u001b[K\n",
            "remote: Compressing objects: 100% (529/529), done.\u001b[K\n",
            "remote: Total 766 (delta 400), reused 552 (delta 214), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (766/766), 11.78 MiB | 3.83 MiB/s, done.\n",
            "Resolving deltas: 100% (400/400), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/DNABERT\n",
        "!python -m pip install --editable .\n",
        "!cd examples\n",
        "!python3 -m pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "Z3tXSZyWDjJu",
        "outputId": "99d7a546-6c16-4dca-8fa1-10e203bf453a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DNABERT\n",
            "Obtaining file:///content/DNABERT\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.0) (1.21.5)\n",
            "Collecting tokenizers==0.5.0\n",
            "  Downloading tokenizers-0.5.0-cp37-cp37m-manylinux1_x86_64.whl (5.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.7 MB 3.2 MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.21.33-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 74.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.0) (3.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.0) (4.63.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.0) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 57.7 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 82.8 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 9.9 MB/s \n",
            "\u001b[?25hCollecting botocore<1.25.0,>=1.24.33\n",
            "  Downloading botocore-1.24.33-py3-none-any.whl (8.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.6 MB 73.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.33->boto3->transformers==2.5.0) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 92.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.33->boto3->transformers==2.5.0) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.0) (2.10)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 88.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.0) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.0) (7.1.2)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, tokenizers, sentencepiece, sacremoses, boto3, transformers\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Running setup.py develop for transformers\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.21.33 botocore-1.24.33 jmespath-1.0.0 s3transfer-0.5.2 sacremoses-0.0.49 sentencepiece-0.1.96 tokenizers-0.5.0 transformers-2.5.0 urllib3-1.25.11\n",
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# model files are at /content/gdrive/MyDrive/Colab Notebooks/6-new-12w-0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X21zUK_hhYJ3",
        "outputId": "83b95a44-7620-49ab-b655-f2c22b1edf02"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "import json\n",
        "\n",
        "with open('/content/DNABERT/6-new-12w-0/config.json', \"rb\") as json_data:\n",
        "    print(json_data)\n",
        "    json_config = json.load(json_data)\n",
        "\n",
        "new_model = tensorflow.keras.models.model_from_json(json_config)\n",
        "\n",
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "Sth3EQ4gg0u7",
        "outputId": "b9eb7e53-8277-4e2f-8a69-8a3518327bb0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_io.BufferedReader name='/content/DNABERT/6-new-12w-0/config.json'>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-30d4eef649ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mjson_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mnew_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/DNABERT/6-new-12w-0/config.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/model_config.py\u001b[0m in \u001b[0;36mmodel_from_json\u001b[0;34m(json_string, custom_objects)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mKeras\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muncompiled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/json_utils.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(json_string)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_decode_helper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparse_constant\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0mkw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parse_constant'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_constant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir finetuned/6\n",
        "\n",
        "!python /content/DNABERT/examples/run_finetune.py \\\n",
        "    --model_type dna \\\n",
        "    --tokenizer_name=dna6 \\\n",
        "    --model_name_or_path '/content/gdrive/MyDrive/Colab Notebooks/6-new-12w-0' \\\n",
        "    --task_name dnaprom \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --data_dir /content/DNABERT/examples/sample_data/ft/6 \\\n",
        "    --max_seq_length 100 \\\n",
        "    --per_gpu_eval_batch_size=32   \\\n",
        "    --per_gpu_train_batch_size=32   \\\n",
        "    --learning_rate 2e-4 \\\n",
        "    --num_train_epochs 5.0 \\\n",
        "    --output_dir /content/DNABERT/finetuned/6 \\\n",
        "    --evaluate_during_training \\\n",
        "    --logging_steps 100 \\\n",
        "    --save_steps 4000 \\\n",
        "    --warmup_percent 0.1 \\\n",
        "    --hidden_dropout_prob 0.1 \\\n",
        "    --overwrite_output \\\n",
        "    --weight_decay 0.01 \\\n",
        "    --n_process 8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byIlSwOXcuWu",
        "outputId": "898a2f9a-08d5-437d-b564-227fd7e203db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘finetuned/6’: File exists\n",
            "04/05/2022 02:30:46 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "04/05/2022 02:30:46 - INFO - transformers.configuration_utils -   loading configuration file /content/gdrive/MyDrive/Colab Notebooks/6-new-12w-0/config.json\n",
            "04/05/2022 02:30:46 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": \"dnaprom\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"num_rnn_layer\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"rnn\": \"lstm\",\n",
            "  \"rnn_dropout\": 0.0,\n",
            "  \"rnn_hidden\": 768,\n",
            "  \"split\": 10,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 4101\n",
            "}\n",
            "\n",
            "============================================================\n",
            "<class 'transformers.tokenization_dna.DNATokenizer'>\n",
            "04/05/2022 02:30:46 - INFO - transformers.tokenization_utils -   loading file https://raw.githubusercontent.com/jerryji1993/DNABERT/master/src/transformers/dnabert-config/bert-config-6/vocab.txt from cache at /root/.cache/torch/transformers/ea1474aad40c1c8ed4e1cb7c11345ddda6df27a857fb29e1d4c901d9b900d32d.26f8bd5a32e49c2a8271a46950754a4a767726709b7741c68723bc1db840a87e\n",
            "04/05/2022 02:30:46 - INFO - transformers.modeling_utils -   loading weights file /content/gdrive/MyDrive/Colab Notebooks/6-new-12w-0/pytorch_model.bin\n",
            "04/05/2022 02:30:51 - INFO - transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
            "04/05/2022 02:30:51 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
            "04/05/2022 02:30:51 - INFO - __main__ -   finish loading model\n",
            "04/05/2022 02:31:02 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, attention_probs_dropout_prob=0.1, beta1=0.9, beta2=0.999, cache_dir='', config_name='', data_dir='/content/DNABERT/examples/sample_data/ft/6', device=device(type='cuda'), do_ensemble_pred=False, do_eval=True, do_lower_case=False, do_predict=False, do_train=True, do_visualize=False, early_stop=0, eval_all_checkpoints=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, hidden_dropout_prob=0.1, learning_rate=0.0002, local_rank=-1, logging_steps=100, max_grad_norm=1.0, max_seq_length=100, max_steps=-1, model_name_or_path='/content/gdrive/MyDrive/Colab Notebooks/6-new-12w-0', model_type='dna', n_gpu=1, n_process=8, no_cuda=False, num_rnn_layer=2, num_train_epochs=5.0, output_dir='/content/DNABERT/finetuned/6', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=32, per_gpu_pred_batch_size=8, per_gpu_train_batch_size=32, predict_dir=None, predict_scan_size=1, result_dir=None, rnn='lstm', rnn_dropout=0.0, rnn_hidden=768, save_steps=4000, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, task_name='dnaprom', tokenizer_name='dna6', visualize_data_dir=None, visualize_models=None, visualize_train=False, warmup_percent=0.1, warmup_steps=0, weight_decay=0.01)\n",
            "04/05/2022 02:31:02 - INFO - __main__ -   Creating features from dataset file at /content/DNABERT/examples/sample_data/ft/6\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   LOOKING AT /content/DNABERT/examples/sample_data/ft/6/train.tsv\n",
            "finish loading examples\n",
            "number of processes for converting feature: 8\n",
            "1 processor started !\n",
            "2 processor started !\n",
            "3 processor started !\n",
            "4 processor started !\n",
            "5 processor started !\n",
            "6 processor started !\n",
            "7 processor started !\n",
            "8 processor started !\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   Writing example 0/4045\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   guid: train-1\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   input_ids: 2 2195 575 2285 936 3731 2623 2285 935 3726 2601 2200 596 2371 1279 1007 4014 3756 2722 2683 2527 1902 3500 1699 2685 2536 1939 3647 2287 943 3759 2734 2732 2722 2681 2520 1876 3396 1284 1026 4091 4062 3948 3492 1665 2549 1991 3853 3112 147 575 2285 936 3732 2625 2296 978 3900 3300 898 3578 2010 3929 3413 1352 1297 1080 212 835 3325 1000 3988 3652 2308 1025 4088 4050 3899 3296 883 3519 1774 2986 3740 2659 2431 1519 1966 3756 2722 2684 2531 1919 3565 1959 3725 2599 3 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   guid: train-2\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   input_ids: 2 2315 1054 105 408 1618 2361 1237 838 3340 1059 127 496 1971 3776 2802 3002 3804 2916 3458 1532 2020 3969 3573 1989 3848 3089 55 205 806 3212 545 2167 461 1830 3209 535 2127 302 1195 669 2661 2437 1543 2061 40 147 573 2280 916 3652 2308 1028 4099 4096 4083 4031 3821 2982 3724 2595 2176 499 1983 3821 2981 3720 2579 2111 239 944 3763 2749 2792 2961 3640 2260 836 3330 1018 4060 3938 3451 1503 1901 3493 1671 2574 2091 159 622 2473 1686 2634 2331 1119 366 3 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   guid: train-3\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   input_ids: 2 3857 3128 212 836 3329 1013 4040 3860 3137 245 965 3846 3084 35 127 495 1967 3760 2740 2756 2818 3067 4063 3951 3501 1704 2708 2627 2304 1012 4036 3844 3075 4095 4078 4011 3744 2673 2488 1747 2880 3314 956 3811 2943 3567 1965 3751 2704 2611 2239 752 2995 3775 2799 2991 3759 2734 2732 2723 2686 2540 1956 3715 2559 2029 4007 3728 2611 2239 750 2988 3748 2689 2552 2002 3898 3292 867 3453 1512 1940 3649 2293 967 3855 3120 180 708 2819 3072 4083 4031 3824 2996 3780 3 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   guid: train-4\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   input_ids: 2 2824 3091 61 229 902 3595 2077 104 402 1596 2276 899 3583 2030 4012 3748 2689 2551 1999 3885 3238 652 2594 2172 482 1913 3544 1874 3385 1238 841 3352 1105 312 1233 824 3283 829 3301 903 3597 2088 147 576 2291 959 3821 2982 3723 2590 2153 406 1612 2339 1150 490 1945 3669 2374 1290 1050 92 356 1411 1533 2021 3975 3597 2086 138 537 2135 333 1318 1164 546 2169 472 1874 3387 1247 879 3504 1716 2753 2805 3013 3845 3078 11 30 106 410 1626 2393 1365 3 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   guid: train-5\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   input_ids: 2 1835 3231 623 2477 1701 2693 2567 2063 45 165 647 2573 2085 133 517 2056 20 68 260 1025 4088 4052 3908 3329 1016 4050 3898 3291 861 3430 1419 1565 2151 399 1581 2215 654 2601 2200 593 2359 1230 810 3226 603 2399 1390 1450 1689 2646 2377 1301 1093 261 1029 5 7 13 39 142 553 2200 593 2360 1236 836 3329 1016 4050 3900 3299 894 3562 1945 3669 2376 1299 1085 232 913 3637 2245 776 3089 53 197 773 3077 5 5 6 9 23 78 297 1173 3 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   Writing example 0/4045\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   guid: train-4046\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   input_ids: 2 1492 1857 3317 968 3857 3128 211 829 3304 916 3651 2303 1008 4017 3767 2766 2858 3227 607 2414 1450 1689 2648 2388 1346 1275 991 3949 3494 1676 2596 2180 513 2039 4047 3887 3248 689 2743 2766 2860 3235 639 2543 1966 3755 2718 2665 2456 1619 2368 1266 954 3801 2904 3409 1336 1236 833 3317 966 3851 3103 110 428 1700 2692 2564 2051 4095 4077 4008 3729 2614 2252 804 3201 501 1990 3849 3093 69 264 1041 56 211 829 3301 904 3602 2106 220 868 3458 1530 2010 3 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   guid: train-4047\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   input_ids: 2 914 3643 2270 876 3490 1657 2518 1865 3351 1103 303 1197 680 2706 2618 2267 861 3431 1421 1576 2194 572 2275 893 3560 1939 3645 2277 903 3598 2091 157 616 2452 1604 2308 1027 4094 4076 4004 3714 2556 2017 3957 3528 1809 3126 201 791 3150 299 1181 616 2451 1598 2282 924 3684 2434 1530 2011 3933 3431 1421 1575 2192 564 2242 762 3036 3937 3446 1483 1822 3178 410 1627 2398 1388 1443 1663 2542 1964 3748 2689 2549 1992 3858 3131 221 871 3472 1587 2239 751 2992 3 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   guid: train-4048\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   input_ids: 2 2049 4086 4042 3865 3159 333 1317 1158 522 2075 96 369 1463 1741 2854 3212 545 2168 465 1846 3274 794 3164 356 1412 1539 2048 4084 4036 3841 3061 4039 3853 3111 141 552 2193 566 2251 799 3181 421 1669 2567 2063 47 174 681 2710 2635 2333 1127 398 1579 2205 615 2447 1583 2221 680 2708 2628 2307 1021 4072 3987 3648 2290 954 3803 2910 3435 1439 1646 2476 1698 2683 2526 1900 3491 1661 2534 1932 3620 2179 511 2029 4008 3731 2621 2277 904 3601 2104 212 835 3 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   guid: train-4049\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   input_ids: 2 67 253 997 3973 3592 2068 65 248 980 3905 3320 980 3905 3317 965 3848 3090 60 225 888 3538 1852 3300 899 3583 2031 4014 3754 2715 2653 2406 1418 1563 2142 364 1443 1661 2536 1939 3647 2288 945 3767 2765 2855 3215 558 2220 676 2692 2564 2052 4099 4093 4071 3982 3628 2210 634 2524 1890 3450 1499 1885 3432 1427 1599 2286 940 3748 2689 2550 1996 3875 3199 495 1967 3760 2740 2756 2819 3070 4075 3999 3695 2480 1716 2755 2814 3052 4003 3709 2536 1940 3651 2301 3 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   guid: train-4050\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   input_ids: 2 1231 813 3240 657 2614 2252 802 3195 478 1900 3489 1656 2514 1849 3285 837 3333 1031 14 44 164 642 2554 2011 3935 3439 1453 1701 2696 2579 2111 237 935 3725 2597 2184 531 2112 243 960 3827 3007 3823 2991 3759 2734 2732 2724 2690 2556 2020 3970 3578 2012 3940 3457 1528 2001 3893 3271 781 3109 136 531 2111 239 942 3754 2715 2655 2414 1451 1694 2667 2463 1646 2475 1696 2675 2495 1773 2981 3719 2573 2088 146 571 2269 869 3463 1550 2091 158 619 2462 1643 3 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   Writing example 0/4045\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   guid: train-8091\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   input_ids: 2 2946 3580 2017 3958 3532 1826 3196 483 1917 3559 1935 3630 2220 674 2681 2520 1874 3387 1246 875 3485 1640 2451 1598 2284 931 3710 2539 1952 3700 2500 1793 3064 4052 3907 3326 1004 4001 3704 2516 1859 3325 1000 3988 3649 2296 977 3893 3270 779 3104 115 446 1770 2972 3681 2421 1479 1807 3118 172 676 2692 2561 2040 4052 3906 3324 996 3969 3573 1992 3858 3130 220 866 3449 1496 1874 3388 1249 888 3539 1854 3308 929 3704 2513 1846 3274 796 3170 380 1507 1919 3565 3 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   guid: train-8092\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   input_ids: 2 3295 879 3501 1704 2707 2622 2282 922 3674 2395 1373 1382 1419 1565 2152 404 1601 2295 974 3883 3231 622 2476 1698 2684 2531 1918 3562 1946 3676 2402 1404 1506 1915 3549 1896 3473 1589 2245 774 3081 24 81 310 1228 803 3199 493 1958 3723 2591 2159 430 1706 2714 2650 2394 1371 1374 1388 1442 1657 2520 1876 3393 1269 968 3860 3137 245 966 3850 3098 89 342 1353 1304 1106 314 1242 860 3428 1409 1528 2001 3893 3272 788 3138 249 984 3921 3384 1234 826 3292 3 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   guid: train-8093\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   input_ids: 2 3543 1870 3370 1178 601 2389 1349 1286 1035 29 104 404 1604 2308 1026 4090 4059 3935 3438 1451 1693 2661 2439 1552 2099 191 750 2988 3748 2692 2563 2047 4080 4019 3773 2790 2953 3607 2126 300 1188 642 2555 2015 3952 3506 1724 2787 2943 3566 1964 3746 2682 2521 1880 3412 1345 1269 967 3855 3117 168 660 2627 2303 1005 4005 3717 2567 2061 40 148 578 2300 996 3969 3576 2002 3900 3297 888 3539 1853 3304 913 3640 2260 836 3331 1021 4069 3976 3602 2108 225 885 3 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   Writing example 0/4045\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   guid: train-8094\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   input_ids: 2 836 3332 1025 4085 4040 3860 3140 260 1025 4085 4040 3859 3133 231 911 3631 2223 688 2740 2756 2820 3075 4096 4083 4032 3827 3008 3827 3008 3825 2997 3784 2836 3140 259 1024 4083 4031 3824 2994 3769 2775 2895 3373 1191 655 2605 2215 655 2607 2223 688 2737 2744 2772 2884 3332 1028 4099 4096 4083 4030 3820 2978 3707 2528 1908 3524 1795 3072 4083 4032 3828 3012 3844 3073 4085 4040 3860 3140 260 1027 4095 4078 4012 3748 2689 2552 2004 3908 3332 1028 4099 4096 4083 4030 3 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   guid: train-12136\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   input_ids: 2 236 932 3716 2561 2037 4040 3860 3137 248 979 3901 3302 908 3619 2176 499 1984 3828 3009 3832 3025 3896 3281 824 3283 829 3304 915 3647 2286 940 3748 2692 2563 2048 4083 4031 3824 2993 3768 2772 2883 3325 1000 3987 3648 2292 964 3844 3074 4092 4067 3966 3563 1952 3700 2498 1786 3035 3935 3439 1456 1716 2753 2808 3026 3900 3297 886 3532 1828 3203 512 2036 4033 3830 3020 3873 3192 468 1859 3326 1004 4003 3711 2542 1964 3746 2684 2529 1912 3539 1856 3314 956 3810 3 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   guid: train-8095\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   input_ids: 2 964 3841 3061 4038 3851 3103 110 426 1691 2655 2416 1457 1719 2767 2863 3245 680 2708 2627 2301 999 3981 3624 2195 573 2280 916 3651 2304 1009 4024 3794 2875 3294 876 3490 1659 2526 1899 3487 1647 2479 1711 2734 2729 2712 2644 2372 1284 1027 4093 4072 3987 3646 2284 932 3716 2561 2040 4049 3896 3282 827 3293 870 3468 1572 2180 515 2045 4070 3977 3608 2131 318 1258 924 3684 2435 1534 2028 4001 3704 2516 1857 3320 979 3902 3307 927 3696 2484 1730 2812 3044 3969 3 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   guid: train-12137\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   input_ids: 2 1493 1862 3337 1046 73 280 1106 314 1242 860 3425 1397 1480 1810 3131 221 872 3476 1602 2297 984 3923 3389 1254 908 3617 2166 457 1815 3151 302 1195 671 2669 2472 1683 2622 2282 922 3676 2402 1402 1499 1886 3434 1434 1626 2396 1380 1411 1534 2026 3993 3672 2388 1345 1270 970 3868 3169 375 1486 1834 3228 612 2435 1533 2021 3974 3596 2083 128 500 1988 3843 3070 4075 3998 3690 2458 1626 2394 1370 1372 1380 1410 1530 2011 3935 3437 1446 1673 2582 2124 289 1141 3 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:02 - INFO - transformers.data.processors.glue -   Writing example 0/4045\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   guid: train-12138\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   input_ids: 2 755 3008 3827 3005 3815 2957 3623 2189 551 2192 563 2237 743 2960 3635 2240 755 3005 3815 2960 3635 2240 755 3005 3815 2960 3635 2239 750 2988 3747 2688 2546 1977 3799 2893 3367 1165 552 2193 568 2260 834 3324 994 3964 3556 1922 3580 2020 3971 3584 2036 4036 3844 3073 4085 4037 3847 3086 43 159 624 2481 1717 2760 2836 3139 253 998 3977 3608 2131 319 1261 935 3728 2612 2242 762 3035 3935 3439 1453 1703 2701 2600 2195 575 2287 942 3755 2718 2668 2468 1667 3 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   guid: train-16181\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   input_ids: 2 1105 310 1226 793 3158 331 1311 1133 421 1670 2570 2075 94 364 1441 1654 2506 1818 3162 346 1369 1365 1352 1298 1083 221 869 3461 1542 2059 29 103 397 1575 2189 549 2182 524 2084 131 510 2028 4004 3716 2563 2045 4072 3988 3651 2302 1002 3995 3679 2415 1455 1709 2725 2693 2567 2063 47 174 684 2724 2691 2557 2021 3973 3592 2066 58 218 858 3419 1373 1382 1418 1564 2147 383 1519 1965 3751 2701 2597 2184 529 2102 204 804 3203 512 2034 4026 3804 2913 3 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   Writing example 0/4045\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   guid: train-16182\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   input_ids: 2 2719 2671 2478 1707 2720 2675 2496 1777 2997 3784 2835 3136 243 957 3813 2951 3597 2088 147 574 2282 924 3684 2435 1536 2034 4027 3808 2932 3524 1796 3073 4088 4051 3903 3309 936 3732 2628 2307 1022 4076 4003 3712 2546 1978 3804 2914 3450 1500 1892 3459 1536 2035 4031 3821 2983 3725 2600 2195 574 2284 932 3715 2559 2029 4005 3720 2580 2114 249 981 3912 3347 1085 232 914 3644 2275 893 3558 1930 3611 2143 367 1453 1703 2703 2606 2219 670 2667 2462 1644 2466 1659 3 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   guid: train-16183\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   input_ids: 2 2310 1033 23 77 296 1169 568 2259 829 3303 911 3629 2213 646 2571 2077 104 404 1602 2300 996 3972 3586 2041 4053 3912 3348 1091 254 1004 4003 3711 2543 1967 3759 2734 2731 2719 2669 2472 1684 2627 2301 1000 3988 3651 2303 1005 4008 3732 2625 2296 979 3901 3303 910 3628 2211 637 2536 1939 3646 2283 927 3695 2477 1702 2699 2591 2157 424 1683 2623 2285 936 3730 2620 2274 890 3548 1891 3454 1515 1949 3686 2444 1572 2177 502 1993 3862 3146 282 1115 349 1382 3 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   guid: train-12139\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   input_ids: 2 3142 265 1046 74 284 1121 373 1477 1800 3090 57 214 842 3353 1112 338 1339 1245 872 3474 1595 2270 874 3483 1630 2409 1431 1615 2349 1191 655 2605 2214 651 2590 2156 420 1666 2556 2020 3970 3577 2005 3910 3339 1054 108 418 1660 2532 1922 3577 2006 3916 3361 1144 467 1855 3309 933 3717 2568 2065 53 200 785 3126 201 789 3142 266 1051 94 364 1444 1666 2556 2018 3962 3545 1877 3400 1300 1090 249 983 3917 3365 1157 518 2057 21 69 262 1034 26 3 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   guid: train-12140\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   input_ids: 2 168 660 2625 2293 968 3859 3135 238 939 3741 2664 2451 1597 2279 909 3621 2184 531 2110 235 927 3694 2476 1697 2678 2506 1818 3161 341 1351 1295 1070 171 670 2668 2467 1663 2541 1959 3725 2598 2187 543 2158 425 1685 2631 2319 1069 167 655 2605 2216 657 2614 2252 804 3203 509 2024 3987 3645 2279 909 3621 2183 526 2091 157 613 2438 1547 2077 104 403 1598 2282 923 3677 2406 1420 1572 2177 502 1994 3866 3164 353 1399 1488 1842 3259 734 2923 3487 1645 3 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   guid: train-20226\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   input_ids: 2 2111 238 940 3748 2690 2554 2010 3932 3427 1405 1512 1937 3638 2252 804 3202 506 2011 3934 3436 1443 1661 2535 1936 3633 2230 713 2838 3148 291 1149 488 1937 3639 2256 819 3263 749 2983 3727 2607 2221 680 2705 2616 2260 834 3322 988 3937 3448 1489 1848 3283 830 3306 923 3677 2408 1427 1597 2279 910 3626 2203 606 2412 1443 1663 2543 1967 3758 2730 2714 2649 2390 1356 1316 1156 513 2039 4045 3878 3211 543 2159 430 1705 2709 2629 2309 1032 17 55 205 808 3 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   guid: train-20227\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   input_ids: 2 2723 2685 2533 1925 3592 2068 65 247 973 3878 3212 545 2165 455 1806 3115 157 614 2443 1567 2158 426 1690 2650 2394 1371 1373 1382 1420 1572 2179 510 2028 4003 3709 2534 1929 3608 2130 313 1238 842 3355 1119 365 1446 1676 2596 2178 508 2018 3961 3542 1865 3350 1098 284 1123 383 1517 1959 3725 2598 2186 538 2138 347 1374 1386 1434 1625 2390 1355 1311 1133 424 1682 2619 2270 873 3478 1611 2333 1126 394 1564 2145 375 1485 1832 3220 579 2301 998 3978 3610 3 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   guid: train-16184\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   input_ids: 2 2522 1883 3421 1383 1421 1574 2185 536 2129 310 1226 793 3157 328 1298 1082 218 860 3427 1405 1512 1937 3640 2258 826 3289 854 3404 1314 1147 477 1894 3465 1557 2118 266 1050 91 349 1382 1420 1569 2168 467 1856 3314 953 3798 2891 3358 1132 418 1659 2525 1896 3473 1592 2257 824 3283 831 3311 942 3754 2714 2652 2401 1397 1480 1812 3139 255 1006 4009 3734 2634 2330 1113 341 1350 1291 1055 109 421 1671 2574 2089 149 584 2321 1079 207 813 3238 650 2586 3 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   guid: train-20228\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   input_ids: 2 2612 2241 759 3021 3879 3213 552 2194 572 2274 891 3550 1899 3487 1647 2477 1701 2696 2579 2111 237 935 3727 2606 2220 674 2681 2520 1875 3389 1256 916 3650 2299 991 3949 3494 1674 2587 2141 359 1421 1575 2189 551 2189 550 2188 546 2171 479 1903 3503 1710 2729 2712 2644 2372 1284 1028 4099 4096 4081 4022 3785 2837 3141 261 1032 17 55 205 805 3205 519 2064 49 184 721 2869 3271 782 3115 158 620 2468 1667 2559 2029 4007 3725 2600 2196 580 2307 1021 3 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   guid: train-16185\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   input_ids: 2 3067 4063 3951 3501 1703 2701 2600 2194 572 2274 892 3556 1923 3582 2026 3994 3675 2400 1396 1475 1791 3055 4016 3762 2748 2787 2942 3564 1954 3708 2531 1918 3564 1956 3715 2560 2035 4031 3822 2988 3747 2685 2535 1934 3626 2203 607 2414 1451 1694 2668 2468 1667 2560 2036 4036 3844 3075 4093 4071 3984 3636 2244 772 3074 4092 4068 3971 3584 2035 4030 3819 2975 3695 2478 1708 2724 2690 2553 2005 3909 3336 1043 61 232 915 3648 2292 963 3839 3053 4008 3732 2628 2308 1028 3 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   guid: train-20229\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   input_ids: 2 3746 2682 2522 1882 3419 1374 1386 1434 1626 2395 1374 1386 1434 1626 2395 1374 1386 1434 1626 2395 1374 1386 1434 1626 2394 1370 1370 1369 1366 1354 1306 1114 346 1370 1372 1377 1400 1489 1847 3277 808 3220 580 2306 1017 4054 3915 3360 1139 446 1771 2974 3692 2466 1659 2525 1894 3467 1567 2157 424 1684 2627 2302 1004 4004 3713 2552 2002 3900 3299 893 3560 1938 3644 2276 898 3580 2019 3965 3557 1926 3595 2077 102 393 1557 2119 270 1067 157 615 2446 1580 2211 637 3 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   Writing example 0/4045\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   guid: train-24271\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   input_ids: 2 3503 1709 2727 2703 2607 2223 686 2732 2723 2686 2540 1955 3709 2536 1939 3646 2281 919 3663 2350 1194 667 2655 2415 1453 1703 2703 2605 2215 656 2611 2238 747 2975 3693 2471 1680 2612 2242 763 3038 3947 3488 1650 2492 1764 2945 3575 1998 3882 3226 603 2398 1386 1435 1629 2408 1428 1601 2293 968 3858 3131 222 875 3488 1651 2494 1771 2975 3695 2480 1716 2755 2813 3048 3987 3648 2291 958 3818 2972 3684 2433 1528 2002 3899 3293 871 3472 1588 2241 758 3020 3876 3202 3 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   guid: train-24272\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   input_ids: 2 938 3739 2654 2410 1433 1621 2374 1289 1046 73 277 1096 273 1077 197 776 3090 60 226 889 3541 1861 3335 1039 46 169 664 2641 2360 1235 830 3306 922 3675 2399 1392 1458 1722 2780 2916 3459 1533 2022 3978 3611 2142 364 1444 1666 2553 2005 3909 3335 1038 43 158 620 2467 1661 2534 1930 3611 2143 366 1449 1687 2639 2349 1191 654 2601 2200 593 2358 1228 804 3203 509 2024 3985 3639 2254 812 3234 633 2519 1869 3368 1169 568 2260 833 3317 967 3853 3109 3 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   guid: train-20230\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   input_ids: 2 1346 1273 982 3914 3354 1115 350 1387 1439 1646 2473 1685 2630 2316 1059 126 491 1950 3691 2463 1647 2478 1707 2719 2671 2479 1710 2729 2712 2643 2365 1255 911 3631 2223 685 2727 2703 2607 2223 685 2725 2693 2567 2061 40 148 579 2303 1007 4015 3757 2728 2706 2620 2274 892 3554 1916 3553 1910 3532 1826 3194 475 1887 3438 1451 1694 2667 2463 1647 2478 1708 2723 2688 2546 1979 3807 2925 3494 1676 2594 2172 482 1914 3547 1886 3435 1437 1638 2442 1564 2146 378 1499 3 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   Writing example 0/4051\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   guid: train-28316\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   input_ids: 2 978 3898 3290 860 3427 1405 1511 1935 3631 2221 679 2701 2599 2191 559 2222 684 2722 2684 2531 1919 3566 1963 3741 2661 2439 1550 2089 150 586 2329 1111 333 1317 1159 525 2086 139 543 2159 431 1711 2734 2732 2721 2680 2516 1860 3329 1015 4046 3883 3229 614 2442 1563 2141 359 1421 1573 2181 518 2059 30 106 411 1630 2409 1432 1619 2366 1259 926 3692 2468 1668 2561 2040 4050 3900 3300 897 3573 1992 3860 3140 257 1015 4046 3884 3234 635 2525 1894 3465 1559 3 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   guid: train-28317\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   input_ids: 2 2462 1643 2463 1645 2470 1676 2596 2178 508 2017 3960 3537 1845 3271 782 3116 161 629 2504 1810 3132 226 892 3556 1922 3580 2019 3967 3567 1966 3755 2718 2668 2468 1666 2556 2020 3969 3574 1993 3861 3142 268 1059 126 491 1949 3685 2437 1543 2063 45 165 647 2575 2093 168 657 2616 2257 822 3276 803 3198 492 1956 3714 2554 2012 3940 3460 1537 2038 4042 3867 3166 362 1436 1633 2421 1477 1798 3083 29 104 404 1604 2306 1018 4060 3938 3452 1505 1912 3540 1859 3 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   guid: train-24273\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   input_ids: 2 478 1900 3491 1661 2536 1940 3652 2307 1023 4077 4006 3724 2595 2175 495 1965 3752 2706 2620 2276 897 3576 2003 3901 3304 915 3645 2280 915 3645 2279 911 3631 2223 687 2734 2729 2712 2641 2360 1236 836 3331 1021 4069 3975 3598 2090 156 612 2434 1532 2019 3966 3563 1949 3687 2446 1580 2209 629 2501 1799 3085 40 147 573 2280 915 3645 2278 905 3606 2124 290 1148 482 1915 3551 1901 3496 1681 2613 2248 786 3132 227 895 3565 1960 3729 2616 2257 823 3280 818 3 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   guid: train-24274\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   input_ids: 2 2445 1574 2187 542 2156 418 1658 2522 1884 3426 1403 1502 1899 3485 1639 2445 1573 2181 518 2059 31 110 426 1690 2652 2403 1407 1517 1960 3730 2620 2273 888 3539 1854 3308 930 3706 2524 1891 3453 1510 1931 3615 2158 426 1691 2653 2408 1425 1591 2256 819 3262 745 2968 3665 2360 1236 836 3329 1016 4051 3902 3306 923 3678 2412 1444 1668 2561 2040 4049 3895 3278 810 3226 602 2395 1374 1385 1429 1606 2313 1047 80 306 1210 730 2905 3416 1361 1335 1230 812 3233 3 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   guid: train-24275\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   input_ids: 2 1005 4005 3720 2577 2101 199 781 3112 148 580 2308 1026 4092 4065 3957 3527 1807 3118 171 672 2675 2494 1772 2980 3715 2560 2035 4030 3819 2973 3688 2451 1597 2280 913 3640 2257 821 3271 781 3109 136 532 2116 259 1021 4071 3982 3626 2203 607 2413 1448 1684 2625 2293 965 3847 3086 43 159 623 2477 1704 2706 2620 2276 899 3582 2026 3995 3679 2413 1445 1669 2567 2062 44 161 632 2513 1845 3269 773 3080 17 53 199 783 3117 165 648 2580 2116 259 1021 3 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   guid: train-28318\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   input_ids: 2 4010 3740 2659 2430 1515 1949 3688 2451 1598 2284 930 3706 2524 1889 3446 1482 1818 3164 354 1404 1508 1924 3586 2041 4056 3923 3390 1260 931 3710 2540 1955 3711 2543 1966 3755 2718 2668 2467 1662 2540 1956 3713 2551 1997 3880 3217 568 2258 828 3297 885 3525 1799 3088 50 188 739 2942 3563 1950 3691 2463 1646 2474 1691 2655 2413 1446 1674 2586 2139 351 1390 1449 1688 2644 2369 1271 974 3883 3230 618 2460 1634 2427 1502 1899 3487 1647 2478 1705 2710 2635 2333 1127 3 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   guid: train-28319\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   input_ids: 2 1964 3748 2690 2556 2017 3959 3533 1829 3208 532 2115 255 1008 4020 3778 2812 3042 3964 3555 1917 3560 1937 3640 2260 836 3331 1021 4072 3985 3640 2260 833 3320 980 3908 3329 1016 4051 3902 3306 923 3678 2410 1435 1631 2416 1459 1727 2797 2983 3725 2599 2192 564 2242 764 3044 3971 3584 2035 4032 3827 3008 3827 3008 3825 3000 3795 2879 3310 939 3743 2671 2477 1701 2693 2568 2065 55 207 816 3252 708 2819 3072 4084 4035 3839 3053 4007 3725 2600 2195 574 2283 927 3 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   guid: train-28320\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   input_ids: 2 3485 1640 2452 1603 2301 997 3976 3604 2116 259 1022 4075 3997 3688 2450 1595 2269 872 3476 1604 2308 1028 4100 4099 4093 4072 3986 3644 2275 895 3565 1960 3732 2627 2303 1007 4013 3752 2706 2620 2276 900 3586 2044 4068 3972 3588 2052 4097 4088 4050 3900 3300 900 3588 2051 4095 4077 4007 3726 2604 2210 635 2525 1896 3473 1592 2260 836 3332 1027 4095 4077 4007 3726 2604 2211 639 2543 1965 3751 2702 2602 2203 608 2420 1474 1788 3043 3966 3564 1955 3710 2540 1956 3714 3 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:31:03 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "04/05/2022 02:31:25 - INFO - __main__ -   Saving features into cached file /content/DNABERT/examples/sample_data/ft/6/cached_train_6-new-12w-0_100_dnaprom\n",
            "04/05/2022 02:31:29 - INFO - __main__ -   ***** Running training *****\n",
            "04/05/2022 02:31:29 - INFO - __main__ -     Num examples = 32366\n",
            "04/05/2022 02:31:29 - INFO - __main__ -     Num Epochs = 5\n",
            "04/05/2022 02:31:29 - INFO - __main__ -     Instantaneous batch size per GPU = 32\n",
            "04/05/2022 02:31:29 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "04/05/2022 02:31:29 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
            "04/05/2022 02:31:29 - INFO - __main__ -     Total optimization steps = 5060\n",
            "04/05/2022 02:31:29 - INFO - __main__ -     Continuing training from checkpoint, will skip to saved global_step\n",
            "04/05/2022 02:31:29 - INFO - __main__ -     Continuing training from epoch 0\n",
            "04/05/2022 02:31:29 - INFO - __main__ -     Continuing training from global step 0\n",
            "04/05/2022 02:31:29 - INFO - __main__ -     Will skip the first 0 steps in the first epoch\n",
            "Epoch:   0% 0/5 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/1012 [00:00<?, ?it/s]\u001b[A/content/DNABERT/src/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
            "\n",
            "Iteration:   0% 1/1012 [00:00<06:44,  2.50it/s]\u001b[A\n",
            "Iteration:   0% 2/1012 [00:00<05:54,  2.85it/s]\u001b[A\n",
            "Iteration:   0% 3/1012 [00:01<05:34,  3.01it/s]\u001b[A\n",
            "Iteration:   0% 4/1012 [00:01<05:25,  3.09it/s]\u001b[A\n",
            "Iteration:   0% 5/1012 [00:01<05:21,  3.14it/s]\u001b[A\n",
            "Iteration:   1% 6/1012 [00:01<05:18,  3.16it/s]\u001b[A\n",
            "Iteration:   1% 7/1012 [00:02<05:16,  3.18it/s]\u001b[A\n",
            "Iteration:   1% 8/1012 [00:02<05:15,  3.19it/s]\u001b[A\n",
            "Iteration:   1% 9/1012 [00:02<05:13,  3.20it/s]\u001b[A\n",
            "Iteration:   1% 10/1012 [00:03<05:12,  3.20it/s]\u001b[A\n",
            "Iteration:   1% 11/1012 [00:03<05:12,  3.21it/s]\u001b[A\n",
            "Iteration:   1% 12/1012 [00:03<05:11,  3.21it/s]\u001b[A\n",
            "Iteration:   1% 13/1012 [00:04<05:10,  3.21it/s]\u001b[A\n",
            "Iteration:   1% 14/1012 [00:04<05:10,  3.22it/s]\u001b[A\n",
            "Iteration:   1% 15/1012 [00:04<05:09,  3.22it/s]\u001b[A\n",
            "Iteration:   2% 16/1012 [00:05<05:09,  3.22it/s]\u001b[A\n",
            "Iteration:   2% 17/1012 [00:05<05:09,  3.22it/s]\u001b[A\n",
            "Iteration:   2% 18/1012 [00:05<05:08,  3.22it/s]\u001b[A\n",
            "Iteration:   2% 19/1012 [00:05<05:08,  3.22it/s]\u001b[A\n",
            "Iteration:   2% 20/1012 [00:06<05:07,  3.22it/s]\u001b[A\n",
            "Iteration:   2% 21/1012 [00:06<05:08,  3.21it/s]\u001b[A\n",
            "Iteration:   2% 22/1012 [00:06<05:08,  3.21it/s]\u001b[A\n",
            "Iteration:   2% 23/1012 [00:07<05:08,  3.21it/s]\u001b[A\n",
            "Iteration:   2% 24/1012 [00:07<05:07,  3.22it/s]\u001b[A\n",
            "Iteration:   2% 25/1012 [00:07<05:06,  3.22it/s]\u001b[A\n",
            "Iteration:   3% 26/1012 [00:08<05:05,  3.22it/s]\u001b[A\n",
            "Iteration:   3% 27/1012 [00:08<05:05,  3.23it/s]\u001b[A\n",
            "Iteration:   3% 28/1012 [00:08<05:05,  3.23it/s]\u001b[A\n",
            "Iteration:   3% 29/1012 [00:09<05:04,  3.22it/s]\u001b[A\n",
            "Iteration:   3% 30/1012 [00:09<05:04,  3.23it/s]\u001b[A\n",
            "Iteration:   3% 31/1012 [00:09<05:03,  3.23it/s]\u001b[A\n",
            "Iteration:   3% 32/1012 [00:10<05:04,  3.22it/s]\u001b[A\n",
            "Iteration:   3% 33/1012 [00:10<05:06,  3.20it/s]\u001b[A\n",
            "Iteration:   3% 34/1012 [00:10<05:05,  3.20it/s]\u001b[A\n",
            "Iteration:   3% 35/1012 [00:10<05:05,  3.20it/s]\u001b[A\n",
            "Iteration:   4% 36/1012 [00:11<05:04,  3.21it/s]\u001b[A\n",
            "Iteration:   4% 37/1012 [00:11<05:03,  3.21it/s]\u001b[A\n",
            "Iteration:   4% 38/1012 [00:11<05:03,  3.21it/s]\u001b[A\n",
            "Iteration:   4% 39/1012 [00:12<05:02,  3.21it/s]\u001b[A\n",
            "Iteration:   4% 40/1012 [00:12<05:02,  3.22it/s]\u001b[A\n",
            "Iteration:   4% 41/1012 [00:12<05:01,  3.22it/s]\u001b[A\n",
            "Iteration:   4% 42/1012 [00:13<05:02,  3.21it/s]\u001b[A\n",
            "Iteration:   4% 43/1012 [00:13<05:01,  3.21it/s]\u001b[A\n",
            "Iteration:   4% 44/1012 [00:13<05:01,  3.21it/s]\u001b[A\n",
            "Iteration:   4% 45/1012 [00:14<05:00,  3.21it/s]\u001b[A\n",
            "Iteration:   5% 46/1012 [00:14<05:00,  3.22it/s]\u001b[A\n",
            "Iteration:   5% 47/1012 [00:14<04:59,  3.22it/s]\u001b[A\n",
            "Iteration:   5% 48/1012 [00:15<04:59,  3.22it/s]\u001b[A\n",
            "Iteration:   5% 49/1012 [00:15<04:59,  3.21it/s]\u001b[A\n",
            "Iteration:   5% 50/1012 [00:15<04:59,  3.21it/s]\u001b[A\n",
            "Iteration:   5% 51/1012 [00:15<04:58,  3.22it/s]\u001b[A\n",
            "Iteration:   5% 52/1012 [00:16<04:59,  3.21it/s]\u001b[A\n",
            "Iteration:   5% 53/1012 [00:16<04:59,  3.20it/s]\u001b[A\n",
            "Iteration:   5% 54/1012 [00:16<04:58,  3.21it/s]\u001b[A\n",
            "Iteration:   5% 55/1012 [00:17<04:58,  3.21it/s]\u001b[A\n",
            "Iteration:   6% 56/1012 [00:17<04:57,  3.22it/s]\u001b[A\n",
            "Iteration:   6% 57/1012 [00:17<04:56,  3.22it/s]\u001b[A\n",
            "Iteration:   6% 58/1012 [00:18<04:56,  3.21it/s]\u001b[A\n",
            "Iteration:   6% 59/1012 [00:18<04:56,  3.22it/s]\u001b[A\n",
            "Iteration:   6% 60/1012 [00:18<04:56,  3.21it/s]\u001b[A\n",
            "Iteration:   6% 61/1012 [00:19<04:56,  3.21it/s]\u001b[A\n",
            "Iteration:   6% 62/1012 [00:19<04:56,  3.20it/s]\u001b[A\n",
            "Iteration:   6% 63/1012 [00:19<04:56,  3.20it/s]\u001b[A\n",
            "Iteration:   6% 64/1012 [00:20<04:55,  3.20it/s]\u001b[A\n",
            "Iteration:   6% 65/1012 [00:20<04:55,  3.21it/s]\u001b[A\n",
            "Iteration:   7% 66/1012 [00:20<04:54,  3.21it/s]\u001b[A\n",
            "Iteration:   7% 67/1012 [00:20<04:54,  3.20it/s]\u001b[A\n",
            "Iteration:   7% 68/1012 [00:21<04:54,  3.21it/s]\u001b[A\n",
            "Iteration:   7% 69/1012 [00:21<04:53,  3.22it/s]\u001b[A\n",
            "Iteration:   7% 70/1012 [00:21<04:52,  3.22it/s]\u001b[A\n",
            "Iteration:   7% 71/1012 [00:22<04:52,  3.22it/s]\u001b[A\n",
            "Iteration:   7% 72/1012 [00:22<04:51,  3.22it/s]\u001b[A\n",
            "Iteration:   7% 73/1012 [00:22<04:51,  3.22it/s]\u001b[A\n",
            "Iteration:   7% 74/1012 [00:23<04:51,  3.22it/s]\u001b[A\n",
            "Iteration:   7% 75/1012 [00:23<04:51,  3.22it/s]\u001b[A\n",
            "Iteration:   8% 76/1012 [00:23<04:50,  3.22it/s]\u001b[A\n",
            "Iteration:   8% 77/1012 [00:24<04:50,  3.22it/s]\u001b[A\n",
            "Iteration:   8% 78/1012 [00:24<04:50,  3.22it/s]\u001b[A\n",
            "Iteration:   8% 79/1012 [00:24<04:50,  3.22it/s]\u001b[A\n",
            "Iteration:   8% 80/1012 [00:24<04:49,  3.21it/s]\u001b[A\n",
            "Iteration:   8% 81/1012 [00:25<04:49,  3.22it/s]\u001b[A\n",
            "Iteration:   8% 82/1012 [00:25<04:49,  3.21it/s]\u001b[A\n",
            "Iteration:   8% 83/1012 [00:25<04:50,  3.20it/s]\u001b[A\n",
            "Iteration:   8% 84/1012 [00:26<04:49,  3.21it/s]\u001b[A\n",
            "Iteration:   8% 85/1012 [00:26<04:48,  3.21it/s]\u001b[A\n",
            "Iteration:   8% 86/1012 [00:26<04:48,  3.21it/s]\u001b[A\n",
            "Iteration:   9% 87/1012 [00:27<04:47,  3.21it/s]\u001b[A\n",
            "Iteration:   9% 88/1012 [00:27<04:47,  3.21it/s]\u001b[A\n",
            "Iteration:   9% 89/1012 [00:27<04:46,  3.22it/s]\u001b[A\n",
            "Iteration:   9% 90/1012 [00:28<04:46,  3.22it/s]\u001b[A\n",
            "Iteration:   9% 91/1012 [00:28<04:45,  3.22it/s]\u001b[A\n",
            "Iteration:   9% 92/1012 [00:28<04:45,  3.22it/s]\u001b[A\n",
            "Iteration:   9% 93/1012 [00:29<04:46,  3.21it/s]\u001b[A\n",
            "Iteration:   9% 94/1012 [00:29<04:46,  3.20it/s]\u001b[A\n",
            "Iteration:   9% 95/1012 [00:29<04:45,  3.21it/s]\u001b[A\n",
            "Iteration:   9% 96/1012 [00:29<04:44,  3.21it/s]\u001b[A\n",
            "Iteration:  10% 97/1012 [00:30<04:44,  3.22it/s]\u001b[A\n",
            "Iteration:  10% 98/1012 [00:30<04:44,  3.22it/s]\u001b[A\n",
            "Iteration:  10% 99/1012 [00:30<04:43,  3.22it/s]\u001b[A04/05/2022 02:32:00 - INFO - __main__ -   Creating features from dataset file at /content/DNABERT/examples/sample_data/ft/6\n",
            "finish loading examples\n",
            "number of processes for converting feature: 2\n",
            "1 processor started !\n",
            "2 processor started !\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   Writing example 0/500\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   guid: dev-1\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   input_ids: 2 3588 2049 4088 4052 3908 3329 1016 4052 3907 3327 1008 4019 3775 2799 2991 3757 2727 2702 2604 2211 637 2536 1940 3650 2300 996 3972 3587 2047 4078 4012 3746 2681 2520 1875 3389 1256 915 3646 2284 931 3709 2535 1935 3630 2220 673 2680 2516 1859 3325 1000 3988 3652 2307 1022 4076 4004 3715 2557 2024 3987 3647 2287 943 3758 2732 2722 2684 2532 1924 3588 2049 4088 4052 3908 3329 1016 4052 3907 3327 1008 4019 3775 2799 2991 3757 2727 2702 2604 2211 637 2536 1940 3650 2300 3 0 0\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   Writing example 0/500\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   guid: dev-2\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   input_ids: 2 3556 1924 3585 2038 4043 3869 3174 396 1570 2169 470 1867 3357 1128 402 1596 2275 893 3560 1939 3647 2286 938 3740 2657 2423 1487 1838 3243 671 2670 2476 1700 2692 2563 2046 4075 3997 3685 2440 1555 2109 230 906 3611 2142 362 1435 1631 2415 1453 1703 2703 2606 2219 669 2661 2439 1551 2094 171 670 2666 2460 1633 2424 1490 1849 3288 851 3390 1260 929 3701 2501 1798 3082 25 87 333 1320 1172 577 2293 967 3853 3110 140 547 2175 493 1959 3727 2605 2215 653 3 0 0\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   guid: dev-501\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   input_ids: 2 2428 1507 1917 3559 1934 3628 2210 633 2520 1876 3393 1270 972 3874 3194 474 1881 3415 1358 1324 1188 643 2557 2022 3979 3615 2159 430 1708 2723 2687 2542 1962 3739 2654 2409 1431 1615 2351 1197 678 2697 2584 2132 322 1276 996 3971 3581 2024 3986 3641 2264 851 3389 1255 910 3626 2203 607 2416 1459 1725 2790 2954 3612 2146 380 1505 1911 3533 1829 3207 527 2093 165 645 2565 2053 6 12 34 123 479 1903 3502 1708 2724 2689 2550 1993 3863 3150 300 1186 636 3 0 0\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   guid: dev-3\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   input_ids: 2 2723 2685 2534 1932 3619 2175 493 1959 3725 2598 2185 536 2131 317 1253 904 3604 2114 252 995 3966 3564 1956 3716 2562 2043 4061 3943 3470 1580 2209 630 2508 1827 3198 489 1941 3655 2317 1062 139 542 2153 405 1605 2311 1037 40 148 580 2308 1027 4095 4077 4008 3732 2626 2300 995 3968 3572 1986 3836 3044 3971 3582 2027 3997 3687 2446 1579 2206 618 2460 1633 2421 1477 1798 3083 31 111 429 1704 2707 2621 2279 910 3626 2202 604 2404 1412 1537 2040 4052 3907 3 0 0\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   guid: dev-502\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   input_ids: 2 3533 1829 3206 524 2084 131 509 2021 3976 3603 2111 238 939 3743 2670 2476 1699 2688 2546 1980 3810 2940 3555 1919 3565 1960 3730 2619 2271 877 3495 1680 2612 2244 771 3069 4071 3982 3628 2210 634 2524 1892 3460 1538 2044 4065 3960 3540 1860 3330 1019 4063 3950 3499 1694 2668 2465 1656 2515 1855 3310 940 3748 2689 2551 1998 3882 3228 611 2429 1510 1932 3619 2173 485 1927 3597 2087 141 552 2196 580 2305 1015 4047 3885 3239 653 2600 2194 572 2275 894 3564 1954 3 0 0\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   guid: dev-4\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   input_ids: 2 1528 2003 3901 3301 904 3604 2115 254 1001 3990 3660 2339 1149 487 1935 3629 2214 649 2583 2125 294 1164 547 2174 491 1950 3692 2465 1656 2514 1852 3300 900 3587 2046 4074 3996 3681 2422 1482 1819 3167 366 1451 1695 2669 2472 1684 2628 2305 1013 4040 3857 3128 212 835 3327 1005 4008 3732 2625 2293 965 3848 3091 61 230 906 3612 2145 374 1484 1826 3196 481 1909 3525 1797 3079 13 40 147 575 2286 938 3738 2651 2399 1391 1454 1706 2716 2659 2431 1517 1958 3 0 0\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   guid: dev-503\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   input_ids: 2 1940 3652 2305 1014 4043 3869 3176 404 1601 2295 976 3891 3264 755 3008 3827 3007 3824 2996 3779 2815 3054 4011 3744 2675 2496 1779 3006 3819 2975 3695 2479 1711 2734 2732 2723 2686 2540 1956 3715 2559 2032 4019 3776 2803 3007 3823 2991 3760 2739 2752 2803 3006 3819 2975 3695 2479 1712 2739 2752 2803 3006 3819 2975 3695 2478 1708 2724 2691 2558 2026 3995 3679 2415 1455 1710 2731 2719 2671 2477 1704 2707 2623 2288 947 3775 2798 2985 3734 2636 2340 1156 513 2040 4052 3906 3 0 0\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   guid: dev-5\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   guid: dev-504\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   input_ids: 2 909 3624 2196 580 2307 1021 4071 3982 3628 2212 642 2556 2020 3969 3576 2004 3908 3329 1016 4051 3903 3311 942 3756 2723 2688 2548 1988 3844 3075 4093 4072 3986 3643 2271 878 3499 1693 2661 2440 1556 2115 255 1006 4011 3743 2672 2484 1729 2806 3020 3876 3204 514 2044 4066 3964 3553 1912 3537 1848 3284 835 3325 999 3983 3632 2228 708 2820 3075 4094 4076 4001 3701 2504 1811 3133 232 915 3645 2278 907 3614 2156 420 1668 2562 2042 4058 3932 3425 1400 1492 1857 3317 3 0 0\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   input_ids: 2 3880 3218 570 2266 860 3426 1404 1506 1915 3549 1893 3464 1555 2109 231 909 3623 2189 552 2194 571 2270 875 3486 1642 2458 1628 2403 1408 1523 1983 3823 2990 3755 2718 2665 2455 1614 2348 1186 634 2523 1885 3432 1426 1594 2265 854 3401 1304 1107 317 1255 910 3628 2210 635 2527 1904 3506 1724 2788 2947 3583 2030 4012 3748 2690 2554 2010 3932 3426 1402 1497 1877 3397 1286 1034 27 93 359 1424 1586 2233 727 2896 3378 1210 729 2901 3400 1300 1090 249 981 3912 3 0 0\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   guid: dev-505\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   input_ids: 2 471 1869 3367 1165 551 2189 551 2190 555 2205 615 2445 1574 2188 547 2173 487 1933 3623 2189 551 2190 555 2206 619 2461 1639 2445 1574 2187 543 2157 423 1677 2599 2190 555 2205 615 2445 1575 2190 555 2205 615 2445 1574 2188 547 2173 487 1933 3623 2189 551 2191 559 2224 691 2751 2798 2986 3739 2653 2408 1427 1597 2279 911 3629 2216 658 2619 2270 876 3489 1653 2504 1812 3137 247 975 3885 3240 659 2622 2284 929 3703 2511 1838 3243 669 2663 2447 1583 3 0 0\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/05/2022 02:32:00 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "04/05/2022 02:32:01 - INFO - __main__ -   Saving features into cached file /content/DNABERT/examples/sample_data/ft/6/cached_dev_6-new-12w-0_100_dnaprom\n",
            "04/05/2022 02:32:01 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "04/05/2022 02:32:01 - INFO - __main__ -     Num examples = 1000\n",
            "04/05/2022 02:32:01 - INFO - __main__ -     Batch size = 32\n",
            "\n",
            "\n",
            "Evaluating:   0% 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:   3% 1/32 [00:00<00:03,  9.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:   6% 2/32 [00:00<00:03,  9.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:   9% 3/32 [00:00<00:02,  9.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  12% 4/32 [00:00<00:02,  9.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  16% 5/32 [00:00<00:02,  9.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  19% 6/32 [00:00<00:02,  9.72it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  22% 7/32 [00:00<00:02,  9.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  25% 8/32 [00:00<00:02,  9.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  28% 9/32 [00:00<00:02,  9.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  31% 10/32 [00:01<00:02,  9.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  34% 11/32 [00:01<00:02,  9.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  38% 12/32 [00:01<00:02,  9.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  41% 13/32 [00:01<00:01,  9.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  44% 14/32 [00:01<00:01,  9.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  47% 15/32 [00:01<00:01,  9.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  50% 16/32 [00:01<00:01,  9.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  53% 17/32 [00:01<00:01,  9.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  56% 18/32 [00:01<00:01,  9.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  59% 19/32 [00:01<00:01,  9.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  62% 20/32 [00:02<00:01,  9.78it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  66% 21/32 [00:02<00:01,  9.78it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  69% 22/32 [00:02<00:01,  9.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  72% 23/32 [00:02<00:00,  9.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  75% 24/32 [00:02<00:00,  9.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  78% 25/32 [00:02<00:00,  9.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  81% 26/32 [00:02<00:00,  9.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  84% 27/32 [00:02<00:00,  9.78it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  88% 28/32 [00:02<00:00,  9.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  91% 29/32 [00:02<00:00,  9.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  94% 30/32 [00:03<00:00,  9.78it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating: 100% 32/32 [00:03<00:00,  9.98it/s]\n",
            "04/05/2022 02:32:04 - INFO - __main__ -   ***** Eval results  *****\n",
            "04/05/2022 02:32:04 - INFO - __main__ -     acc = 0.686\n",
            "04/05/2022 02:32:04 - INFO - __main__ -     auc = 0.8513520000000001\n",
            "04/05/2022 02:32:04 - INFO - __main__ -     f1 = 0.6592881944444444\n",
            "04/05/2022 02:32:04 - INFO - __main__ -     mcc = 0.4490082311142989\n",
            "04/05/2022 02:32:04 - INFO - __main__ -     precision = 0.770979020979021\n",
            "04/05/2022 02:32:04 - INFO - __main__ -     recall = 0.6859999999999999\n",
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "{\"eval_acc\": 0.686, \"eval_f1\": 0.6592881944444444, \"eval_mcc\": 0.4490082311142989, \"eval_auc\": 0.8513520000000001, \"eval_precision\": 0.770979020979021, \"eval_recall\": 0.6859999999999999, \"learning_rate\": 3.9525691699604744e-05, \"loss\": 0.6596332177519798, \"step\": 100}\n",
            "\n",
            "Iteration:  10% 100/1012 [00:35<23:36,  1.55s/it]\u001b[A\n",
            "Iteration:  10% 101/1012 [00:35<17:55,  1.18s/it]\u001b[A\n",
            "Iteration:  10% 102/1012 [00:35<13:57,  1.09it/s]\u001b[A\n",
            "Iteration:  10% 103/1012 [00:36<11:09,  1.36it/s]\u001b[A\n",
            "Iteration:  10% 104/1012 [00:36<09:12,  1.64it/s]\u001b[A\n",
            "Iteration:  10% 105/1012 [00:36<07:51,  1.92it/s]\u001b[A\n",
            "Iteration:  10% 106/1012 [00:37<06:53,  2.19it/s]\u001b[A\n",
            "Iteration:  11% 107/1012 [00:37<06:13,  2.42it/s]\u001b[A\n",
            "Iteration:  11% 108/1012 [00:37<05:45,  2.62it/s]\u001b[A\n",
            "Iteration:  11% 109/1012 [00:38<05:25,  2.77it/s]\u001b[A\n",
            "Iteration:  11% 110/1012 [00:38<05:12,  2.88it/s]\u001b[A\n",
            "Iteration:  11% 111/1012 [00:38<05:04,  2.96it/s]\u001b[A\n",
            "Iteration:  11% 112/1012 [00:39<04:56,  3.04it/s]\u001b[A\n",
            "Iteration:  11% 113/1012 [00:39<04:50,  3.09it/s]\u001b[A\n",
            "Iteration:  11% 114/1012 [00:39<04:46,  3.13it/s]\u001b[A\n",
            "Iteration:  11% 115/1012 [00:40<04:43,  3.16it/s]\u001b[A\n",
            "Iteration:  11% 116/1012 [00:40<04:42,  3.18it/s]\u001b[A\n",
            "Iteration:  12% 117/1012 [00:40<04:40,  3.19it/s]\u001b[A\n",
            "Iteration:  12% 118/1012 [00:40<04:39,  3.20it/s]\u001b[A\n",
            "Iteration:  12% 119/1012 [00:41<04:38,  3.21it/s]\u001b[A\n",
            "Iteration:  12% 120/1012 [00:41<04:38,  3.20it/s]\u001b[A\n",
            "Iteration:  12% 121/1012 [00:41<04:38,  3.20it/s]\u001b[A\n",
            "Iteration:  12% 122/1012 [00:42<04:37,  3.21it/s]\u001b[A\n",
            "Iteration:  12% 123/1012 [00:42<04:38,  3.19it/s]\u001b[A\n",
            "Iteration:  12% 124/1012 [00:42<04:37,  3.20it/s]\u001b[A\n",
            "Iteration:  12% 125/1012 [00:43<04:36,  3.21it/s]\u001b[A\n",
            "Iteration:  12% 126/1012 [00:43<04:35,  3.21it/s]\u001b[A\n",
            "Iteration:  13% 127/1012 [00:43<04:34,  3.22it/s]\u001b[A\n",
            "Iteration:  13% 128/1012 [00:44<04:34,  3.22it/s]\u001b[A\n",
            "Iteration:  13% 129/1012 [00:44<04:34,  3.22it/s]\u001b[A\n",
            "Iteration:  13% 130/1012 [00:44<04:34,  3.22it/s]\u001b[A\n",
            "Iteration:  13% 131/1012 [00:44<04:34,  3.21it/s]\u001b[A\n",
            "Iteration:  13% 132/1012 [00:45<04:33,  3.22it/s]\u001b[A\n",
            "Iteration:  13% 133/1012 [00:45<04:33,  3.21it/s]\u001b[A\n",
            "Iteration:  13% 134/1012 [00:45<04:32,  3.22it/s]\u001b[A\n",
            "Iteration:  13% 135/1012 [00:46<04:32,  3.22it/s]\u001b[A\n",
            "Iteration:  13% 136/1012 [00:46<04:32,  3.22it/s]\u001b[A\n",
            "Iteration:  14% 137/1012 [00:46<04:32,  3.21it/s]\u001b[A\n",
            "Iteration:  14% 138/1012 [00:47<04:31,  3.22it/s]\u001b[A\n",
            "Iteration:  14% 139/1012 [00:47<04:31,  3.22it/s]\u001b[A\n",
            "Iteration:  14% 140/1012 [00:47<04:31,  3.21it/s]\u001b[A\n",
            "Iteration:  14% 141/1012 [00:48<04:31,  3.21it/s]\u001b[A\n",
            "Iteration:  14% 142/1012 [00:48<04:30,  3.21it/s]\u001b[A\n",
            "Iteration:  14% 143/1012 [00:48<04:30,  3.21it/s]\u001b[A\n",
            "Iteration:  14% 144/1012 [00:49<04:29,  3.22it/s]\u001b[A\n",
            "Iteration:  14% 145/1012 [00:49<04:29,  3.22it/s]\u001b[A\n",
            "Iteration:  14% 146/1012 [00:49<04:29,  3.21it/s]\u001b[A\n",
            "Iteration:  15% 147/1012 [00:49<04:29,  3.21it/s]\u001b[A\n",
            "Iteration:  15% 148/1012 [00:50<04:28,  3.22it/s]\u001b[A\n",
            "Iteration:  15% 149/1012 [00:50<04:28,  3.22it/s]\u001b[A\n",
            "Iteration:  15% 150/1012 [00:50<04:29,  3.20it/s]\u001b[A\n",
            "Iteration:  15% 151/1012 [00:51<04:29,  3.20it/s]\u001b[A\n",
            "Iteration:  15% 152/1012 [00:51<04:28,  3.21it/s]\u001b[A\n",
            "Iteration:  15% 153/1012 [00:51<04:27,  3.21it/s]\u001b[A\n",
            "Iteration:  15% 154/1012 [00:52<04:26,  3.22it/s]\u001b[A\n",
            "Iteration:  15% 155/1012 [00:52<04:26,  3.22it/s]\u001b[A\n",
            "Iteration:  15% 156/1012 [00:52<04:25,  3.22it/s]\u001b[A\n",
            "Iteration:  16% 157/1012 [00:53<04:25,  3.22it/s]\u001b[A\n",
            "Iteration:  16% 158/1012 [00:53<04:25,  3.22it/s]\u001b[A\n",
            "Iteration:  16% 159/1012 [00:53<04:24,  3.22it/s]\u001b[A\n",
            "Iteration:  16% 160/1012 [00:54<04:25,  3.21it/s]\u001b[A\n",
            "Iteration:  16% 161/1012 [00:54<04:25,  3.20it/s]\u001b[A\n",
            "Iteration:  16% 162/1012 [00:54<04:25,  3.21it/s]\u001b[A\n",
            "Iteration:  16% 163/1012 [00:54<04:24,  3.21it/s]\u001b[A\n",
            "Iteration:  16% 164/1012 [00:55<04:23,  3.22it/s]\u001b[A\n",
            "Iteration:  16% 165/1012 [00:55<04:22,  3.22it/s]\u001b[A\n",
            "Iteration:  16% 166/1012 [00:55<04:22,  3.22it/s]\u001b[A\n",
            "Iteration:  17% 167/1012 [00:56<04:22,  3.22it/s]\u001b[A\n",
            "Iteration:  17% 168/1012 [00:56<04:22,  3.22it/s]\u001b[A\n",
            "Iteration:  17% 169/1012 [00:56<04:21,  3.22it/s]\u001b[A\n",
            "Iteration:  17% 170/1012 [00:57<04:21,  3.22it/s]\u001b[A\n",
            "Iteration:  17% 171/1012 [00:57<04:21,  3.22it/s]\u001b[A\n",
            "Iteration:  17% 172/1012 [00:57<04:21,  3.22it/s]\u001b[A\n",
            "Iteration:  17% 173/1012 [00:58<04:20,  3.22it/s]\u001b[A\n",
            "Iteration:  17% 174/1012 [00:58<04:20,  3.22it/s]\u001b[A\n",
            "Iteration:  17% 175/1012 [00:58<04:19,  3.22it/s]\u001b[A\n",
            "Iteration:  17% 176/1012 [00:58<04:19,  3.23it/s]\u001b[A\n",
            "Iteration:  17% 177/1012 [00:59<04:18,  3.22it/s]\u001b[A\n",
            "Iteration:  18% 178/1012 [00:59<04:18,  3.23it/s]\u001b[A\n",
            "Iteration:  18% 179/1012 [00:59<04:18,  3.23it/s]\u001b[A\n",
            "Iteration:  18% 180/1012 [01:00<04:17,  3.23it/s]\u001b[A\n",
            "Iteration:  18% 181/1012 [01:00<04:17,  3.23it/s]\u001b[A\n",
            "Iteration:  18% 182/1012 [01:00<04:17,  3.22it/s]\u001b[A\n",
            "Iteration:  18% 183/1012 [01:01<04:17,  3.22it/s]\u001b[A\n",
            "Iteration:  18% 184/1012 [01:01<04:16,  3.22it/s]\u001b[A\n",
            "Iteration:  18% 185/1012 [01:01<04:16,  3.22it/s]\u001b[A"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "riSGC3QOeJgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir prediction/6\n",
        "\n",
        "!python /content/DNABERT/examples/run_finetune.py \\\n",
        "    --model_type dna \\\n",
        "    --tokenizer_name=dna6 \\\n",
        "    --model_name_or_path /content/DNABERT/finetuned/6 \\\n",
        "    --task_name dnaprom \\\n",
        "    --do_predict \\\n",
        "    --data_dir /content/DNABERT/examples/sample_data/ft/6  \\\n",
        "    --max_seq_length 75 \\\n",
        "    --per_gpu_pred_batch_size=128   \\\n",
        "    --output_dir /content/DNABERT/finetuned/6 \\\n",
        "    --predict_dir /content/DNABERT/prediction \\\n",
        "    --n_process 48"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9awhb0omcuTC",
        "outputId": "9eba7e42-57a4-46cc-fe57-d0a461c86780"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "04/05/2022 02:28:37 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/DNABERT/src/transformers/configuration_utils.py\", line 225, in get_config_dict\n",
            "    raise EnvironmentError\n",
            "OSError\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/DNABERT/examples/run_finetune.py\", line 1284, in <module>\n",
            "    main()\n",
            "  File \"/content/DNABERT/examples/run_finetune.py\", line 1063, in main\n",
            "    cache_dir=args.cache_dir if args.cache_dir else None,\n",
            "  File \"/content/DNABERT/src/transformers/configuration_utils.py\", line 176, in from_pretrained\n",
            "    config_dict, kwargs = cls.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "  File \"/content/DNABERT/src/transformers/configuration_utils.py\", line 241, in get_config_dict\n",
            "    raise EnvironmentError(msg)\n",
            "OSError: Model name '/content/DNABERT/finetuned/6' was not found in model name list. We assumed 'https://s3.amazonaws.com/models.huggingface.co/bert//content/DNABERT/finetuned/6/config.json' was a path, a model identifier, or url to a configuration file named config.json or a directory containing such a file but couldn't find any such file at this path or url.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RFL9AtJ6cuK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ur7oKQQrcuIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xm2dSrmLcuEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kzGG7n1_cuA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iEyQCUZzct9M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}